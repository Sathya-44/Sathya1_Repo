{"cells":[{"source":"# Practical Exam: Supermarket Loyalty\n\nInternational Essentials is an international supermarket chain.\n\nShoppers at their supermarkets can sign up for a loyalty program that provides rewards each year to customers based on their spending. The more you spend the bigger the rewards. \n\nThe supermarket would like to be able to predict the likely amount customers in the program will spend, so they can estimate the cost of the rewards. \n\nThis will help them to predict the likely profit at the end of the year.\n\n## Data\n\nThe dataset contains records of customers for their last full year of the loyalty program.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|\n","metadata":{},"id":"0a8ca74a-b235-4034-9c1c-3159336a39d5","cell_type":"markdown"},{"source":"# Task 1\n\nBefore you fit any models, you will need to make sure the data is clean. \n\nThe table below shows what the data should look like. \n\nCreate a cleaned version of the dataframe. \n\n - You should start with the data in the file \"loyalty.csv\". \n\n - Your output should be a dataframe named `clean_data`. \n\n - All column names and values should match the table below.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n|customer_id | Unique identifier for the customer. </br>Missing values are not possible due to the database structure. |\n|spend | Continuous. </br>The total spend of the customer in their last full year. This can be any positive value to two decimal places. </br>Missing values should be replaced with 0. |\n|first_month | Continuous. </br>The amount spent by the customer in their first month of the year. This can be any positive value, rounded to two decimal places. </br>Missing values should be replaced with 0. |\n| items_in_first_month | Discrete. </br>The number of items purchased in the first month. Any integer value greater than or equal to zero. </br>Missing values should be replaced by 0. |  \n| region | Nominal. </br>The geographic region that the customer is based in. One of four values Americas, Asia/Pacific, Europe, Middle East/Africa. </br>Missing values should be replaced with \"Unknown\". |\n| loyalty_years | Oridinal. </br>The number of years the customer has been a part of the loyalty program. One of five ordered categories, '0-1', '1-3', '3-5', '5-10', '10+'. </br>Missing values should be replaced with '0-1'.|\n| joining_month | Nominal. </br>The month the customer joined the loyalty program. One of 12 values \"Jan\", \"Feb\", \"Mar\", \"Apr\", etc. </br>Missing values should be replaced with \"Unknown\".|\n| promotion | Nominal. </br>Did the customer join the loyalty program as part of a promotion? Either 'Yes' or 'No'. </br>Missing values should be replaced with 'No'.|","metadata":{},"id":"790f8bb8-76fb-44fd-8078-c62909a91b2b","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 1\n\n#Task1\n\n# Write your answer to Task 1 here\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport re\nimport os\nfrom IPython.display import FileLink\n\n#reading data\ndf1=pd.read_csv(\"loyalty.csv\")\ncolumn_list = list(df1.columns)\ndf1.dtypes","metadata":{"executionCancelledAt":null,"executionTime":42,"lastExecutedAt":1757766346634,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 1\n\n#Task1\n\n# Write your answer to Task 1 here\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport re\nimport os\nfrom IPython.display import FileLink\n\n#reading data\ndf1=pd.read_csv(\"loyalty.csv\")\ncolumn_list = list(df1.columns)\ndf1.dtypes","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{}}}},"id":"523dd03c-8591-4cc6-b750-d71da287745f","cell_type":"code","execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":"customer_id               int64\nspend                   float64\nfirst_month              object\nitems_in_first_month      int64\nregion                   object\nloyalty_years            object\njoining_month            object\npromotion                object\ndtype: object"},"metadata":{"application/com.datacamp.data-table.v1+json":{"status":"error","error":"Maximum recursion level reached"},"application/com.datacamp.data-table.v2+json":{"status":"error","error":"Maximum recursion level reached"}},"execution_count":23}]},{"source":"# Droping duplicates and empty rows in DataFrame\n\ndef quick_clean(df):                 #defining function\n    return df.dropna().drop_duplicates().reset_index(drop=True)\n\ndf1=quick_clean(df1)\ndf1.shape","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1757766346684,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Droping duplicates and empty rows in DataFrame\n\ndef quick_clean(df):                 #defining function\n    return df.dropna().drop_duplicates().reset_index(drop=True)\n\ndf1=quick_clean(df1)\ndf1.shape","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"32222199-c7f4-4dce-83f0-a16ad47775ef","nodeType":"const"}}}}},"cell_type":"code","id":"154e09ca-d7b9-447e-885d-a06405a7851c","outputs":[{"output_type":"execute_result","data":{"text/plain":"(1121, 8)"},"metadata":{},"execution_count":24}],"execution_count":24},{"source":"#defining function to check column null or empty and display summary\ncolumn_list = list(df1.columns)\ndef check_all_columns_empty(df,column_list=None,show_details=True):\n     # If no column list provided, use all columns\n    if column_list is None:\n        column_list = df.columns.tolist()\n    results = {}\n    for col in column_list:\n        if col in df.columns:\n            results[col] = {\n                'null': df[col].isnull().sum(),\n                'empty': (df[col].astype(str).str.strip() == '').sum(),\n                'nan': df[col].isna().sum(),\n                'special_chars': df[col].astype(str).str.contains(r'[^a-zA-Z0-9\\s]', na=False).sum()\n            }\n        else:\n            print(f\"Warning: Column '{col}' not found in DataFrame\")\n    if show_details:\n        for col, issues in results.items():\n            print(f\"{col}: {issues}\")\n    return results\n\n# Usage\nNull_summary= check_all_columns_empty(df1)\n","metadata":{"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1757766346752,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#defining function to check column null or empty and display summary\ncolumn_list = list(df1.columns)\ndef check_all_columns_empty(df,column_list=None,show_details=True):\n     # If no column list provided, use all columns\n    if column_list is None:\n        column_list = df.columns.tolist()\n    results = {}\n    for col in column_list:\n        if col in df.columns:\n            results[col] = {\n                'null': df[col].isnull().sum(),\n                'empty': (df[col].astype(str).str.strip() == '').sum(),\n                'nan': df[col].isna().sum(),\n                'special_chars': df[col].astype(str).str.contains(r'[^a-zA-Z0-9\\s]', na=False).sum()\n            }\n        else:\n            print(f\"Warning: Column '{col}' not found in DataFrame\")\n    if show_details:\n        for col, issues in results.items():\n            print(f\"{col}: {issues}\")\n    return results\n\n# Usage\nNull_summary= check_all_columns_empty(df1)\n","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"1c08b8fd-bc6f-4800-94cd-3a5c775d4dcd","outputs":[{"output_type":"stream","name":"stdout","text":"customer_id: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nspend: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\nfirst_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1112}\nitems_in_first_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nregion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 558}\nloyalty_years: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\njoining_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\npromotion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\n"}],"execution_count":25},{"source":"#customer_id\n# Remove any duplicate customer_id if they exist (keep first occurrence)\ndf1 = df1.drop_duplicates(subset=['customer_id'], keep='first')\ndf1 = df1.dropna(subset=['customer_id'])\ndf1.shape","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1757766346800,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#customer_id\n# Remove any duplicate customer_id if they exist (keep first occurrence)\ndf1 = df1.drop_duplicates(subset=['customer_id'], keep='first')\ndf1 = df1.dropna(subset=['customer_id'])\ndf1.shape","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"32222199-c7f4-4dce-83f0-a16ad47775ef","nodeType":"const"}}}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"4c255757-6b96-47ff-850a-ebab2b2ca799","outputs":[{"output_type":"execute_result","data":{"text/plain":"(1121, 8)"},"metadata":{},"execution_count":26}],"execution_count":26},{"source":"#Spend\n#Check if it has negative value\nprint(\"Spend has negative values:\", (df1['spend'] < 0).any())\n#print(df1['spend'].unique())","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1757766346848,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Spend\n#Check if it has negative value\nprint(\"Spend has negative values:\", (df1['spend'] < 0).any())\n#print(df1['spend'].unique())","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"7905dd78-c87b-48e4-b180-5603d59938ad","outputs":[{"output_type":"stream","name":"stdout","text":"Spend has negative values: False\n"}],"execution_count":27},{"source":"#Define function to check and convert negativw values to positive\ndef convert_to_positive(df, column):\n    \"\"\"Simple function to check if column is numeric and convert negatives to positive\"\"\"\n    \n    # Check if column exists\n    if column not in df.columns:\n        print(f\"Column '{column}' not found\")\n        return df\n    \n    # Check if column is numeric (int or float)\n    if df[column].dtype in ['int64', 'float64', 'int32', 'float32']:\n        negative_count = (df[column] < 0).sum()\n        print(f\"Column '{column} dtype: {df[column].dtype}\")\n        if negative_count > 0:\n            print(f\"Converting {negative_count} negative values to positive in '{column}'\")\n            df[column] = df[column].abs()\n        else:\n            print(f\"No negative values found in '{column}'\")\n    else:\n        print(f\"Column '{column}' is not numeric (int/float)\")\n    \n    return df\n","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766346904,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Define function to check and convert negativw values to positive\ndef convert_to_positive(df, column):\n    \"\"\"Simple function to check if column is numeric and convert negatives to positive\"\"\"\n    \n    # Check if column exists\n    if column not in df.columns:\n        print(f\"Column '{column}' not found\")\n        return df\n    \n    # Check if column is numeric (int or float)\n    if df[column].dtype in ['int64', 'float64', 'int32', 'float32']:\n        negative_count = (df[column] < 0).sum()\n        print(f\"Column '{column} dtype: {df[column].dtype}\")\n        if negative_count > 0:\n            print(f\"Converting {negative_count} negative values to positive in '{column}'\")\n            df[column] = df[column].abs()\n        else:\n            print(f\"No negative values found in '{column}'\")\n    else:\n        print(f\"Column '{column}' is not numeric (int/float)\")\n    \n    return df\n"},"cell_type":"code","id":"6f21f4a6-52b4-4ccc-bc12-013324d49ae5","outputs":[],"execution_count":28},{"source":"#Usage\n#Spend\ndf1 = convert_to_positive(df1, 'spend')\ndf1['spend']=df1['spend'].round(2)\n#df1['spend'].unique()","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1757766346952,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Usage\n#Spend\ndf1 = convert_to_positive(df1, 'spend')\ndf1['spend']=df1['spend'].round(2)\n#df1['spend'].unique()","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"7ec0053e-b3ec-4c15-895b-4028ca17babc","outputs":[{"output_type":"stream","name":"stdout","text":"Column 'spend dtype: float64\nNo negative values found in 'spend'\n"}],"execution_count":29},{"source":"#first_month\n#Check null,empty nan and convert to numeric and roundoff\ndf1['first_month']=pd.to_numeric(df1['first_month'], errors='coerce')\n#df1['first_month'].dtype\ndf1=convert_to_positive(df1,'first_month')\ndf1['first_month'].unique()\n\n#check null\nNull_summary= check_all_columns_empty(df1)","metadata":{"executionCancelledAt":null,"executionTime":72,"lastExecutedAt":1757766347024,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#first_month\n#Check null,empty nan and convert to numeric and roundoff\ndf1['first_month']=pd.to_numeric(df1['first_month'], errors='coerce')\n#df1['first_month'].dtype\ndf1=convert_to_positive(df1,'first_month')\ndf1['first_month'].unique()\n\n#check null\nNull_summary= check_all_columns_empty(df1)","outputsMetadata":{"0":{"height":227,"type":"stream"}}},"cell_type":"code","id":"0d978a77-376f-426f-87e3-19122f28987f","outputs":[{"output_type":"stream","name":"stdout","text":"Column 'first_month dtype: float64\nNo negative values found in 'first_month'\ncustomer_id: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nspend: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\nfirst_month: {'null': 113, 'empty': 0, 'nan': 113, 'special_chars': 1008}\nitems_in_first_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nregion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 558}\nloyalty_years: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\njoining_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\npromotion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\n"}],"execution_count":30},{"source":"#first_month\ndf1['first_month']=df1['first_month'].replace('nan',0).fillna(0).round(2)\n#check null\nNull_summary= check_all_columns_empty(df1)\n#df1['first_month'].unique()","metadata":{"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1757766347092,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#first_month\ndf1['first_month']=df1['first_month'].replace('nan',0).fillna(0).round(2)\n#check null\nNull_summary= check_all_columns_empty(df1)\n#df1['first_month'].unique()","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"da7667b5-f493-4b51-bc7a-de1c120165ba","outputs":[{"output_type":"stream","name":"stdout","text":"customer_id: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nspend: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\nfirst_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\nitems_in_first_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\nregion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 558}\nloyalty_years: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 1121}\njoining_month: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\npromotion: {'null': 0, 'empty': 0, 'nan': 0, 'special_chars': 0}\n"}],"execution_count":31},{"source":"#items_in_first_month\n\ndf1 = convert_to_positive(df1, 'items_in_first_month')\ndf1['items_in_first_month']=df1['items_in_first_month']\ndf1['items_in_first_month']=df1['items_in_first_month'].replace('nan',0).fillna(0)\ndf1['items_in_first_month'].unique()","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1757766347140,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#items_in_first_month\n\ndf1 = convert_to_positive(df1, 'items_in_first_month')\ndf1['items_in_first_month']=df1['items_in_first_month']\ndf1['items_in_first_month']=df1['items_in_first_month'].replace('nan',0).fillna(0)\ndf1['items_in_first_month'].unique()","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"0c356075-35ed-436c-bc18-951156992e72","outputs":[{"output_type":"stream","name":"stdout","text":"Column 'items_in_first_month dtype: int64\nNo negative values found in 'items_in_first_month'\n"},{"output_type":"execute_result","data":{"text/plain":"array([ 5, 14,  7,  8, 13,  9,  6, 12, 11, 10, 15])"},"metadata":{},"execution_count":32}],"execution_count":32},{"source":"#region\ndf1['region']=df1['region'].replace('nan','Unknown').fillna('Unknown').astype('category')\ndf1['region'].dtype","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766347196,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#region\ndf1['region']=df1['region'].replace('nan','Unknown').fillna('Unknown').astype('category')\ndf1['region'].dtype"},"cell_type":"code","id":"0eb6e0b9-bb72-4718-94b5-0f5f0e498fd1","outputs":[{"output_type":"execute_result","data":{"text/plain":"CategoricalDtype(categories=['Americas', 'Asia/Pacific', 'Europe', 'Middle East/Africa'], ordered=False)"},"metadata":{},"execution_count":33}],"execution_count":33},{"source":"#loyalty_years\ndf1['loyalty_years']=df1['loyalty_years'].replace('nan','0-1').fillna('0-1').astype('category')\ndf1['loyalty_years'].dtype\ndf1['loyalty_years'].unique()","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766347252,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#loyalty_years\ndf1['loyalty_years']=df1['loyalty_years'].replace('nan','0-1').fillna('0-1').astype('category')\ndf1['loyalty_years'].dtype\ndf1['loyalty_years'].unique()","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"c354039f-c3e9-465f-8049-0c4f42e00d1c","outputs":[{"output_type":"execute_result","data":{"text/plain":"['5-10', '0-1', '10+', '3-5', '1-3']\nCategories (5, object): ['0-1', '1-3', '10+', '3-5', '5-10']"},"metadata":{},"execution_count":34}],"execution_count":34},{"source":"#joining_month\ndf1['joining_month']=df1['joining_month'].replace('nan','Unknown').fillna('Unknown').str.title().astype('category')\ndf1['joining_month'].dtype\ndf1['joining_month'].unique()","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766347308,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#joining_month\ndf1['joining_month']=df1['joining_month'].replace('nan','Unknown').fillna('Unknown').str.title().astype('category')\ndf1['joining_month'].dtype\ndf1['joining_month'].unique()"},"cell_type":"code","id":"c2f0d98b-1b86-42b7-b8ba-8c7bab8a344f","outputs":[{"output_type":"execute_result","data":{"text/plain":"['Nov', 'Feb', 'Dec', 'Apr', 'May', ..., 'Jan', 'Sep', 'Mar', 'Jun', 'Aug']\nLength: 12\nCategories (12, object): ['Apr', 'Aug', 'Dec', 'Feb', ..., 'May', 'Nov', 'Oct', 'Sep']"},"metadata":{},"execution_count":35}],"execution_count":35},{"source":"#promotion\n#df1['promotion'].unique()\ndf1['promotion']=df1['promotion'].replace('nan','No').fillna('No').str.title().astype('category')\ndf1['promotion'].dtype\ndf1['promotion'].unique()","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766347364,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#promotion\n#df1['promotion'].unique()\ndf1['promotion']=df1['promotion'].replace('nan','No').fillna('No').str.title().astype('category')\ndf1['promotion'].dtype\ndf1['promotion'].unique()"},"cell_type":"code","id":"ba7bf9c2-ba0f-49cd-860a-4f92d255b4d4","outputs":[{"output_type":"execute_result","data":{"text/plain":"['No', 'Yes']\nCategories (2, object): ['No', 'Yes']"},"metadata":{},"execution_count":36}],"execution_count":36},{"source":"#check\ndf1.dtypes\n\nclean_data=df1","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1757766347416,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#check\ndf1.dtypes\n\nclean_data=df1"},"cell_type":"code","id":"91b5398c-0859-4a2a-883f-a51f26efb244","outputs":[],"execution_count":37},{"source":"# Task 2 \n\nThe team at International Essentials have told you that they have always believed that the number of years in the loyalty scheme is the biggest driver of spend. \n\nProducing a table showing the difference in the average spend by number of years in the loyalty programme along with the variance to investigate this question for the team.\n\n - You should start with the data in the file 'loyalty.csv'.\n\n - Your output should be a data frame named `spend_by_years`. \n\n - It should include the three columns `loyalty_years`, `avg_spend`, `var_spend`. \n\n - Your answers should be rounded to 2 decimal places.   ","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"08b695b7-67db-48fb-8b14-e12bb5a9620e","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 2\n# Write your answer to Task 1 here\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport re\nimport os\nfrom IPython.display import FileLink\n\n#reading data\ndf1=pd.read_csv(\"loyalty.csv\")\ncolumn_list = list(df1.columns)\ndf1.dtypes","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1757766347468,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 2\n# Write your answer to Task 1 here\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport re\nimport os\nfrom IPython.display import FileLink\n\n#reading data\ndf1=pd.read_csv(\"loyalty.csv\")\ncolumn_list = list(df1.columns)\ndf1.dtypes","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"id":"cc590298-c483-4253-bef1-a352933cbd5e","cell_type":"code","execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":"customer_id               int64\nspend                   float64\nfirst_month              object\nitems_in_first_month      int64\nregion                   object\nloyalty_years            object\njoining_month            object\npromotion                object\ndtype: object"},"metadata":{"application/com.datacamp.data-table.v1+json":{"status":"error","error":"Maximum recursion level reached"},"application/com.datacamp.data-table.v2+json":{"status":"error","error":"Maximum recursion level reached"}},"execution_count":38}]},{"source":"#groupby\nspend_by_years=df1.groupby('loyalty_years').agg(\n    avg_spend = ('spend', 'mean'),\n    var_spend = ('spend', 'var')\n).round(2).reset_index()\nprint(spend_by_years)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1757766347524,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#groupby\nspend_by_years=df1.groupby('loyalty_years').agg(\n    avg_spend = ('spend', 'mean'),\n    var_spend = ('spend', 'var')\n).round(2).reset_index()\nprint(spend_by_years)","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"44da13e1-3d73-4cc5-af3b-600e9a0e1f14","outputs":[{"output_type":"stream","name":"stdout","text":"  loyalty_years  avg_spend  var_spend\n0           0-1     110.56       9.30\n1           1-3     129.31       9.65\n2           10+     117.41      16.72\n3           3-5     124.55      11.09\n4          5-10     135.15      14.10\n"}],"execution_count":39},{"source":"# Task 3\n\nFit a baseline model to predict the spend over the year for each customer.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “test.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `customer_id` and `spend`. The `spend` column must be your predicted values.","metadata":{},"id":"7113acde-8a74-487a-8983-f0c93003d945","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 3\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load the data\ntrain_df = pd.read_csv('train.csv')\ntest_df = pd.read_csv('test.csv')\n\nprint(\"Train data shape:\", train_df.shape)\nprint(\"Test data shape:\", test_df.shape)\nprint(\"\\nTrain columns:\", train_df.columns.tolist())\nprint(\"Test columns:\", test_df.columns.tolist())\n\n# Check for missing values\nprint(\"\\nMissing values in train:\", train_df.isnull().sum())\nprint(\"Missing values in test:\", test_df.isnull().sum())\n\n# Basic statistics\nprint(\"\\nTrain data info:\")\nprint(train_df.describe())","metadata":{"executionCancelledAt":null,"executionTime":545,"lastExecutedAt":1757766678381,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 3\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load the data\ntrain_df = pd.read_csv('train.csv')\ntest_df = pd.read_csv('test.csv')\n\nprint(\"Train data shape:\", train_df.shape)\nprint(\"Test data shape:\", test_df.shape)\nprint(\"\\nTrain columns:\", train_df.columns.tolist())\nprint(\"Test columns:\", test_df.columns.tolist())\n\n# Check for missing values\nprint(\"\\nMissing values in train:\", train_df.isnull().sum())\nprint(\"Missing values in test:\", test_df.isnull().sum())\n\n# Basic statistics\nprint(\"\\nTrain data info:\")\nprint(train_df.describe())","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"id":"79a77f11-b09b-4d70-893b-535dfde919b2","cell_type":"code","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":"Train data shape: (996, 8)\nTest data shape: (250, 7)\n\nTrain columns: ['customer_id', 'spend', 'first_month', 'items_in_first_month', 'region', 'loyalty_years', 'joining_month', 'promotion']\nTest columns: ['customer_id', 'first_month', 'items_in_first_month', 'region', 'loyalty_years', 'joining_month', 'promotion']\n\nMissing values in train: customer_id             0\nspend                   0\nfirst_month             0\nitems_in_first_month    0\nregion                  0\nloyalty_years           0\njoining_month           0\npromotion               0\ndtype: int64\nMissing values in test: customer_id             0\nfirst_month             0\nitems_in_first_month    0\nregion                  0\nloyalty_years           0\njoining_month           0\npromotion               0\ndtype: int64\n\nTrain data info:\n       customer_id       spend  first_month  items_in_first_month\ncount   996.000000  996.000000   996.000000            996.000000\nmean    624.411647  129.286948    18.722018              9.139558\nstd     359.492637   26.823041     4.138861              3.261100\nmin       1.000000   65.540000    10.970000              4.000000\n25%     312.250000  129.807500    15.397500              6.000000\n50%     623.500000  140.490000    20.145000              8.000000\n75%     938.250000  146.282500    22.000000             12.000000\nmax    1246.000000  154.050000    25.900000             15.000000\n"}]},{"source":"# Task 4\n\nFit a comparison model to predict the spend over the year for each customer.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “test.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `customer_id` and `spend`. The `spend` column must be your predicted values.","metadata":{},"id":"44033abf-a603-479e-8663-9a96fefee5a2","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 4","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1757766347624,"lastExecutedByKernel":"075effce-93b1-47fb-8d2c-eab59deb1c37","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 4"},"id":"731cfa01-2709-413a-ac19-611e73e37c75","cell_type":"code","execution_count":41,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}